Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length
2000,1.7916704,0.00029100303,-0.6709744,-0.000999990850687027,-0.0009998884052038193,985.0
3000,1.7915547,0.000285003,-1.0016606,-0.5000000186264515,-0.4999998948769644,985.0
4000,1.7915552,0.00027900303,-1.039647,2.000000234693289,2.000000249943696,985.0
5000,1.7915239,0.00027300304,-1.0305946,1.2665987014770508e-07,1.7113052308559418e-07,985.0
6000,1.786625,0.00026700302,-0.604506,9.685754776000977e-08,1.7113052308559418e-07,985.0
7000,1.782835,0.000261003,-0.8540882,1.1175870895385742e-08,8.172355592250824e-08,985.0
8000,1.7852826,0.00025500305,-0.66232806,1.0000001192092896,1.000000154133886,985.0
9000,1.7868484,0.00024900303,-0.56820303,4.0,4.000000083935447,985.0
10000,1.7858297,0.00024300304,-0.6884606,1.5000000335276127,1.500000154133886,985.0
11000,1.7763003,0.00023700304,-0.8753382,0.5000000931322575,0.5000000881263986,985.0
12000,1.7826545,0.00023100304,-0.604339,1.0000001788139343,1.000000154133886,985.0
13000,1.7774956,0.00022500305,-0.7708927,2.5000001415610313,2.5000002563465387,985.0
14000,1.7802812,0.00021900305,-0.6463977,1.999999761581421,2.000000005122274,985.0
15000,1.7803227,0.00021300303,-0.6792177,-1.6763806343078613e-07,-1.4086253941059113e-08,985.0
16000,1.7816128,0.00020700306,-0.39960718,3.5000003203749657,3.500000328756869,985.0
