Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length
1000,1.7524087,0.0002985015,-0.13055816,-0.6016000000759959,-0.6016000000759959,180.2
2000,1.7573848,0.0002955015,-0.09592882,-0.3333333333333333,-0.3333333333333333,174.33333333333334
3000,1.7536902,0.0002925015,-0.14700295,-0.6670000000158325,-0.6670000000158325,165.5
4000,1.7507454,0.00028950154,-0.057041023,0.3326666666350017,0.3326666666350017,162.66666666666666
5000,1.7559224,0.00028650148,-0.20301399,-0.6002000000094995,-0.6002000000094995,166.0
6000,1.7615991,0.00028350152,-0.1601817,-0.33383333335708204,-0.33383333335708204,176.5
7000,1.764736,0.00028050155,-0.19462359,-0.33366666668249917,-0.33366666668249917,170.33333333333334
8000,1.7693877,0.00027750153,-0.22729905,-0.6678333333499419,-0.6678333333887471,179.66666666666666
9000,1.7585144,0.00027450154,-0.17139359,0.19859999995678662,0.19859999993350358,160.8
10000,1.7467381,0.0002715015,-0.26083294,-1.0002500000118744,-1.0002500000118744,276.25
11000,1.7432067,0.00026850155,-0.28978005,-0.3343333333420257,-0.33433333338083077,175.33333333333334
12000,1.736877,0.0002655015,-0.17171288,0.19939999997150154,0.19939999997150154,173.0
13000,1.7298381,0.00026250153,-0.19604559,-0.3348333334045795,-0.3348333334045795,167.83333333333334
