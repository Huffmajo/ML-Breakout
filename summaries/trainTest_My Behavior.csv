Steps,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length,Losses/Value Loss,Losses/Policy Loss
2000,1.074642,0.00029992504,0.0,-24.360647,3.043744201099293,3.0437444537087384,169.03333333333333,212.61916,0.036374543
4000,1.0848337,0.00029977507,0.0,-20.534185,2.9438834042877566,2.9438836777777877,162.25510204081633,82.3593,0.035132322
6000,1.0189105,0.00029962504,0.0,-17.964466,2.9322342079853674,2.9322346106649864,150.33653846153845,40.542725,0.034451995
8000,1.0021161,0.00029947504,0.0,-14.327299,2.897590166976992,2.8975905619994387,147.85849056603774,22.404684,0.033702794
10000,0.95760596,0.00029932504,0.0,-10.064025,2.968149615035285,2.968149998087588,153.40384615384616,10.549794,0.035830088
12000,0.96794194,0.00029917504,0.0,-7.48121,2.987016342658535,2.9870166701728826,162.78125,6.248373,0.03330088
14000,0.9641898,0.00029902507,0.0,-5.6497226,3.15111923860473,3.151119588316207,166.02061855670104,3.836523,0.03197779
16000,0.9347785,0.00029887503,0.0,-4.178252,3.5358285875585986,3.5358289186539427,187.18072289156626,2.1880713,0.030021697
