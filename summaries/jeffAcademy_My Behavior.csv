Steps,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length,Losses/Value Loss,Losses/Policy Loss
4986,0.030100275,0.00029992522,0.0,-696.7045,3.9254011511802673,3.925400107531459,370.0,15683.546,0.12356087
9986,6.2557106e-29,0.00029977545,0.0,-985.6755,-497.58781012147665,-497.5876993564889,4961.0,26119.867,0.023003845
14986,0.0,0.00029962545,0.0,-1049.3147,-501.00013595819473,-501.0000243782997,4961.0,36865.805,0.024170268
19986,0.0,0.00029947542,0.0,-695.13916,-501.00013595819473,-501.0000243782997,4961.0,20726.525,0.02519125
24986,0.0,0.00029932542,0.0,-598.02747,-501.00013595819473,-501.0000243782997,4961.0,18568.8,0.025632178
29986,0.0,0.00029917544,0.0,-436.477,-501.00013595819473,-501.0000243782997,4961.0,30729.42,0.024161924
34986,0.0,0.00029902544,0.0,-358.13608,-501.00013595819473,-501.0000243782997,4961.0,6701.102,0.023477744
